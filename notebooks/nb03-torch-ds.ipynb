{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T03:32:07.275984Z",
     "start_time": "2020-06-09T03:32:07.249550Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T03:32:15.232014Z",
     "start_time": "2020-06-09T03:32:07.376953Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai2.text.all import L, test_eq\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel\n",
    "import warnings\n",
    "\n",
    "from htools import *\n",
    "from stormlight.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T03:32:17.322014Z",
     "start_time": "2020-06-09T03:32:17.253189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/hmamin/stormlight\n"
     ]
    }
   ],
   "source": [
    "cd_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T03:32:17.621087Z",
     "start_time": "2020-06-09T03:32:17.557386Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_book(book):\n",
    "    return load(PATHS[book])[slice(*BOOK_IDX[book])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T03:32:17.882867Z",
     "start_time": "2020-06-09T03:32:17.828061Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_books(*books):\n",
    "    return DotDict((book, load_book(book)) for book in books or PATHS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T03:32:18.284007Z",
     "start_time": "2020-06-09T03:32:18.224892Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_clean(book, *args):\n",
    "    print('Length:', len(book))\n",
    "    print('Page breaks:', book.count(BREAK))\n",
    "    print('Feed form chars:', book.count('\\x0c'))\n",
    "    for arg in args:\n",
    "        print(repr(arg) + ':', book.count(arg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T03:32:18.697828Z",
     "start_time": "2020-06-09T03:32:18.594563Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_pages(book, n=150, end=True, max_pages=None):\n",
    "    for page in book.split(BREAK)[:max_pages]:\n",
    "        print(page[:n])\n",
    "        if end:\n",
    "            print(spacer(n_chars=3))\n",
    "            print(page[-n:])\n",
    "        print(spacer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T03:32:19.727713Z",
     "start_time": "2020-06-09T03:32:19.683359Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_endnotes(book):\n",
    "    return load(PATHS[book])[BOOK_IDX[book][-1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T03:34:05.004291Z",
     "start_time": "2020-06-19T03:34:04.873864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge': 'xxbrxxPROLOGUE\\n\\nLift had never robbed a palace bef',\n",
       " 'war': \"xxbrxxPrologue\\n\\nIt's funny, Vasher thought, how ma\",\n",
       " 'kings': 'xxbrxxPRELUDE TO\\n\\nTHE STORMLIGHT ARCHIVE\\n\\nKalak ro',\n",
       " 'words': 'xxbrxxSIX YEARS AGO\\nJasnah Kholin pretended to enj',\n",
       " 'oath': 'xxbrxxSIX YEARS AGO\\nEshonai had always told her si'}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = load_books(*NOVELLAS+STORMLIGHT)\n",
    "{k: v[:50] for k, v in books.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:45:56.266080Z",
     "start_time": "2020-06-08T00:45:56.169876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge\n",
      "Length: 287754\n",
      "Page breaks: 159\n",
      "Feed form chars: 0\n",
      "'\\n': 5024\n",
      "'\\n\\n': 185\n",
      "\n",
      "\n",
      "war\n",
      "Length: 1116087\n",
      "Page breaks: 575\n",
      "Feed form chars: 0\n",
      "'\\n': 18216\n",
      "'\\n\\n': 959\n",
      "\n",
      "\n",
      "kings\n",
      "Length: 2200799\n",
      "Page breaks: 1456\n",
      "Feed form chars: 0\n",
      "'\\n': 32501\n",
      "'\\n\\n': 1585\n",
      "\n",
      "\n",
      "words\n",
      "Length: 2285222\n",
      "Page breaks: 1113\n",
      "Feed form chars: 0\n",
      "'\\n': 38305\n",
      "'\\n\\n': 1133\n",
      "\n",
      "\n",
      "oath\n",
      "Length: 2600942\n",
      "Page breaks: 946\n",
      "Feed form chars: 0\n",
      "'\\n': 35206\n",
      "'\\n\\n': 49\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Way of Kings has fewer words per page. Keep in mind for later decisions.\n",
    "for name, text in books.items():\n",
    "    print(name)\n",
    "    check_clean(text, '\\n', '\\n\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T04:05:22.199343Z",
     "start_time": "2020-06-13T04:05:20.235610Z"
    }
   },
   "outputs": [],
   "source": [
    "tok = GPT2TokenizerFast.from_pretrained('gpt2', pad_token='<|endoftext|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T04:05:22.956049Z",
     "start_time": "2020-06-13T04:05:22.884580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50257, 50257)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tok), tok.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T04:05:25.104840Z",
     "start_time": "2020-06-13T04:05:25.048606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special = dict(additional_special_tokens=[BREAK])\n",
    "tok.add_special_tokens(special)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T04:05:25.998989Z",
     "start_time": "2020-06-13T04:05:25.935855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|endoftext|>',\n",
       " 'eos_token': '<|endoftext|>',\n",
       " 'unk_token': '<|endoftext|>',\n",
       " 'pad_token': '<|endoftext|>',\n",
       " 'additional_special_tokens': ['xxbrxx']}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T04:05:27.722026Z",
     "start_time": "2020-06-13T04:05:27.645232Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('xxbrxx', '')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode([50257]), tok.decode([50258])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T04:05:29.704448Z",
     "start_time": "2020-06-13T04:05:29.622357Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50258, 50257)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tok), tok.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:46:10.790726Z",
     "start_time": "2020-06-08T00:46:09.960166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4904.000000\n",
       "mean       14.369494\n",
       "std         9.778607\n",
       "min         1.000000\n",
       "25%         7.000000\n",
       "50%        12.000000\n",
       "75%        19.000000\n",
       "90%        27.000000\n",
       "91%        28.000000\n",
       "92%        29.000000\n",
       "93%        30.000000\n",
       "94%        31.000000\n",
       "95%        33.000000\n",
       "96%        35.000000\n",
       "97%        37.000000\n",
       "98%        40.000000\n",
       "99%        45.000000\n",
       "max        83.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = [len(tok.encode(line)) for line in books.edge.split('.') if line]\n",
    "pd.Series(lengths).describe(percentiles=np.r_[.25:.8:.25, .9:1:.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:46:11.539162Z",
     "start_time": "2020-06-08T00:46:11.298599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    158.000000\n",
       "mean     470.582278\n",
       "std      118.312509\n",
       "min       27.000000\n",
       "25%      421.250000\n",
       "50%      508.500000\n",
       "75%      554.500000\n",
       "90%      572.600000\n",
       "91%      574.870000\n",
       "92%      576.440000\n",
       "93%      578.060000\n",
       "94%      584.000000\n",
       "95%      586.150000\n",
       "96%      587.720000\n",
       "97%      588.580000\n",
       "98%      597.740000\n",
       "99%      604.870000\n",
       "max      633.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = [len(tok.encode(pg)) for pg in books.edge.split(BREAK) if pg]\n",
    "pd.Series(lengths).describe(percentiles=np.r_[.25:.8:.25, .9:1:.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:46:15.080320Z",
     "start_time": "2020-06-08T00:46:14.956219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del lengths; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:46:17.518026Z",
     "start_time": "2020-06-08T00:46:17.474931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[74, 282, 17072, 6807, 3371, 262, 19516]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.encode('kaladin walked towards the cliff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:46:18.662691Z",
     "start_time": "2020-06-08T00:46:18.613777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 k\n",
      "282 al\n",
      "17072 adin\n",
      "6807  walked\n",
      "3371  towards\n",
      "262  the\n",
      "19516  cliff\n"
     ]
    }
   ],
   "source": [
    "for n in [74, 282, 17072, 6807, 3371, 262, 19516]:\n",
    "    print(n, tok.decode([n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:46:22.490504Z",
     "start_time": "2020-06-08T00:46:22.450283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.max_len, tok.max_len_single_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T03:43:47.665518Z",
     "start_time": "2020-06-13T03:43:47.549436Z"
    }
   },
   "outputs": [],
   "source": [
    "class LMDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, books=tuple(PATHS.keys()), tok=None, seq_len=512,\n",
    "                 tokens=None, subset_frac=1, return_tuple=False):\n",
    "        if not tok and tokens is None:\n",
    "            raise ValueError('Must pass in either tokenizer or tokens.')\n",
    "        self.books = books\n",
    "        self.tok = tok\n",
    "        self.seq_len = seq_len\n",
    "        self.subset_frac = subset_frac\n",
    "        self.tokens = self._create_tokens() if tokens is None else tokens\n",
    "        self.return_tuple = return_tuple\n",
    "        \n",
    "    def _create_tokens(self):\n",
    "        books = load_books(*self.books)\n",
    "        text = BREAK.join(book[:int(len(book)*self.subset_frac)] \n",
    "                          for book in books.values())\n",
    "        tokens = self.tok.encode(text)\n",
    "            \n",
    "        # Instead of padding/dropping last batch, load last book's endnotes.\n",
    "        n_missing = self.seq_len - len(tokens) % self.seq_len\n",
    "        if n_missing > 0:\n",
    "            endnotes = load_endnotes(self.books[-1])\n",
    "            tokens += self.tok.encode(endnotes)[:n_missing]\n",
    "        return np.array(tokens)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        seq = self.tokens[i*self.seq_len:(i+1)*self.seq_len]\n",
    "        return (seq, seq) if self.return_tuple else seq\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.tokens) / self.seq_len))\n",
    "    \n",
    "    def save(self, path):\n",
    "        data = select(vars(self), drop=['tok'])\n",
    "        data['tok_type'] = type(self.tok)\n",
    "        save(data, path)\n",
    "        \n",
    "    @classmethod\n",
    "    def from_pickle(cls, path, tok=None, **kwargs):\n",
    "        data = load(path)\n",
    "        data.update(kwargs)\n",
    "        if type(tok) != data.pop('tok_type'):\n",
    "            warnings.warn('Tokenizer is different than what was used to '\n",
    "                          'tokenize data.')\n",
    "        return cls(tok=tok, **data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T04:57:02.533445Z",
     "start_time": "2020-06-12T04:57:02.463557Z"
    }
   },
   "outputs": [],
   "source": [
    "size2kwargs = {'tiny': dict(seq_len=16, subset_frac=0.01),\n",
    "               'med': dict(seq_len=512, subset_frac=0.05),\n",
    "               'all': dict(seq_len=512, subset_frac=1)}\n",
    "ds_paths = {sz: f'data/datasets/gpt2_lm_tokens_{sz}.pkl' \n",
    "            for sz in size2kwargs}\n",
    "\n",
    "bs = 4\n",
    "shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T04:57:43.231785Z",
     "start_time": "2020-06-12T04:57:03.723141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data to data/datasets/gpt2_lm_tokens_tiny.pkl.\n",
      "Writing data to data/datasets/gpt2_lm_tokens_med.pkl.\n",
      "Writing data to data/datasets/gpt2_lm_tokens_all.pkl.\n"
     ]
    }
   ],
   "source": [
    "for sz, kwargs in size2kwargs.items():\n",
    "    ds = LMDataset(tok=tok, **kwargs)\n",
    "    ds.save(ds_paths[sz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T03:33:08.738345Z",
     "start_time": "2020-06-09T03:33:06.514169Z"
    }
   },
   "outputs": [],
   "source": [
    "# ~40 sec to create DS for all 6 books w/ seq_len=512 and frac=1\n",
    "ds = LMDataset(tok=tok, seq_len=seq_len, subset_frac=subset_frac)\n",
    "dl = DataLoader(ds, batch_size=bs, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:46:58.277763Z",
     "start_time": "2020-06-08T00:46:58.212669Z"
    }
   },
   "outputs": [],
   "source": [
    "assert all(x.shape[-1] == dl.dataset.seq_len for x in dl),\\\n",
    "    'Batch sizes differ. Check if last batch is incomplete.'\n",
    "if ds.seq_len == 512 and ds.books == tuple(PATHS.keys()):\n",
    "    ds.save(ds_paths['all'])\n",
    "    test_eq(ds.tokens, LMDataset.from_pickle(ds_all_path, tok).tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:46:58.442310Z",
     "start_time": "2020-06-08T00:46:58.382160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0:  sight. I\n",
      "wouldn't send my own brother ashore there without guards, and he's killed\n",
      " 1: 've revised my earlier\n",
      "decision. I need you to halt the ship and let me inspect the\n",
      " 2:  as other men might play with their mustaches. \"Brightness,\n",
      "that's not advisable.\n",
      " 3:  I've experienced one or two\n",
      "times in my life.\"\n",
      "\"No, I simply cannot allow\n"
     ]
    }
   ],
   "source": [
    "eprint(tok.decode(block[:20]) for block in item(dl).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T03:33:13.472561Z",
     "start_time": "2020-06-09T03:33:13.419008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((122250,), 2445)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.tokens.shape, len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T03:33:13.973513Z",
     "start_time": "2020-06-09T03:33:13.912515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50258, 50257)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tok), tok.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Situation: Initially, we are using pre-trained weights so loss is relatively low and text generation works fairly well. However, the model can't handle the new xxbrxx token and will throw an error when it appears (embedding matrix is 1 row too small).\n",
    "\n",
    "If we resize the model's embedding matrix, we no longer get errors but now loss is high and text generation is terrible. My hope is that the untrained embedding and new row in the last linear layer is just really bad this point and training a bit will fix this problem. My worry is that something's not working correctly (e.g. indices are shifted when the new row is added so they no longer correspond to the right embeddings).\n",
    "\n",
    "Ways to check:\n",
    "- examine rows of model.transformer.wte before and after resize. Only the last one should change.\n",
    "- Train a bit and see if the issue disappears.\n",
    "- logic: if everything was shifted by one, we'd expect to see nonsense generation but there would still be variety in token choices. Because we're seeing xxbrxx output repeatedly, I'm guessing that's not an issue here.\n",
    "\n",
    "Followup: After resizing embedding, generating text while preventing the model from choosing the xxbrxx token gives us results similar to before resizing. Therefore, I'm pretty sure this is just reflecting the fact that there are some\n",
    "untrained weights now, which should be fixed by training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T03:13:13.039850Z",
     "start_time": "2020-06-10T03:13:06.133400Z"
    }
   },
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tok.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T04:04:59.895772Z",
     "start_time": "2020-06-09T04:04:59.760718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Embedding(50257, 768), 50258, 50257)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.wte, len(tok), tok.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T04:05:00.203048Z",
     "start_time": "2020-06-09T04:04:59.901699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0445, -0.0548,  0.0123,  ...,  0.1044,  0.0978, -0.0695],\n",
       "        [ 0.1860,  0.0167,  0.0461,  ..., -0.0963,  0.0785, -0.0225],\n",
       "        [ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.wte.weight[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T04:05:03.744863Z",
     "start_time": "2020-06-09T04:05:02.923903Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.tensor(ds[44])\n",
    "    loss, logits, past = model(x, labels=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T04:05:04.938462Z",
     "start_time": "2020-06-09T04:05:04.882893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.5749),\n",
       " torch.Size([50, 50257]),\n",
       " [torch.Size([2, 1, 12, 50, 64]),\n",
       "  torch.Size([2, 1, 12, 50, 64]),\n",
       "  torch.Size([2, 1, 12, 50, 64]),\n",
       "  torch.Size([2, 1, 12, 50, 64]),\n",
       "  torch.Size([2, 1, 12, 50, 64]),\n",
       "  torch.Size([2, 1, 12, 50, 64]),\n",
       "  torch.Size([2, 1, 12, 50, 64]),\n",
       "  torch.Size([2, 1, 12, 50, 64]),\n",
       "  torch.Size([2, 1, 12, 50, 64]),\n",
       "  torch.Size([2, 1, 12, 50, 64]),\n",
       "  torch.Size([2, 1, 12, 50, 64]),\n",
       "  torch.Size([2, 1, 12, 50, 64])])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, logits.shape, attrmap('shape', *past)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T04:05:42.993025Z",
     "start_time": "2020-06-09T04:05:10.408254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Huqin turned to one of his companions. Using their ropes, they scuttled the building and reached an area with a few buildings in it that could be considered as part \"Shuaai\".\\n\"I am about ready.\" said Jinxiu Feng from within Wu Hua Tower\\'s walls! This was also not surprising considering how many people came here just now (but still there were lots already). But he had no idea what did go on inside this space or where all those who went out yesterday got into… but at least for today everyone would'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tok.encode(['Huqin turned to one of his companions. Using their ropes, they scuttled'])\n",
    "gen = model.generate(torch.tensor(x).unsqueeze(0), max_length=112, min_length=10, \n",
    "                      repetition_penalty=10, no_repeat_ngram_size=4,\n",
    "                      early_stopping=True, do_sample=True, temperature=.7)\n",
    "tok.decode(gen.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T04:05:56.027553Z",
     "start_time": "2020-06-09T04:05:55.957325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As expected, got RuntimeError(index out of range: Tried to access index 50257 out of table with 50256 rows. at ../aten/src/TH/generic/THTensorEvenMoreMath.cpp:418).\n"
     ]
    }
   ],
   "source": [
    "with assert_raises(RuntimeError):\n",
    "    with torch.no_grad():\n",
    "        x = torch.tensor(ds[0])\n",
    "        loss, logits, past = model(x, labels=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T04:05:59.388102Z",
     "start_time": "2020-06-09T04:05:57.854210Z"
    }
   },
   "outputs": [],
   "source": [
    "model.resize_token_embeddings(len(tok))\n",
    "model.tie_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T04:06:00.098479Z",
     "start_time": "2020-06-09T04:06:00.032773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50258, 768])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.wte.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T04:06:00.826897Z",
     "start_time": "2020-06-09T04:06:00.731471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0445, -0.0548,  0.0123,  ...,  0.1044,  0.0978, -0.0695],\n",
       "        [ 0.1860,  0.0167,  0.0461,  ..., -0.0963,  0.0785, -0.0225],\n",
       "        [ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207],\n",
       "        [ 0.0071, -0.0033,  0.0120,  ...,  0.0155,  0.0073, -0.0005]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.wte.weight[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T04:06:11.768892Z",
     "start_time": "2020-06-09T04:06:11.349552Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.tensor(ds[0])\n",
    "    loss, logits, past = model(x, labels=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T04:06:12.310958Z",
     "start_time": "2020-06-09T04:06:12.257085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(91.3928)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T04:06:13.872954Z",
     "start_time": "2020-06-09T04:06:13.815982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 50258])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logits: (seq_len, vocab_sz), maybe (bs, seq_len, vocab_sz) if bs > 1\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T04:06:15.244508Z",
     "start_time": "2020-06-09T04:06:15.192559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([2, 1, 12, 50, 64]),\n",
       " torch.Size([2, 1, 12, 50, 64]),\n",
       " torch.Size([2, 1, 12, 50, 64]),\n",
       " torch.Size([2, 1, 12, 50, 64]),\n",
       " torch.Size([2, 1, 12, 50, 64]),\n",
       " torch.Size([2, 1, 12, 50, 64]),\n",
       " torch.Size([2, 1, 12, 50, 64]),\n",
       " torch.Size([2, 1, 12, 50, 64]),\n",
       " torch.Size([2, 1, 12, 50, 64]),\n",
       " torch.Size([2, 1, 12, 50, 64]),\n",
       " torch.Size([2, 1, 12, 50, 64]),\n",
       " torch.Size([2, 1, 12, 50, 64])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keys and values in attention blocks: (2, batch_size, num_heads, sequence_length, embed_size_per_head))\n",
    "attrmap('shape', *past)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T04:02:28.896437Z",
     "start_time": "2020-06-20T04:02:28.843609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 50])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(iter(dl))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T00:59:12.809218Z",
     "start_time": "2020-06-08T00:59:10.262050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"xxbrxxPROLOGUE\\n\\nLift had never robbed a palace before. Seemed like a dangerous thing to try.\\nNot because she might get caught, but because once you robbed a starvin'\\npalace, where did you go next?xxbrxx PRxxbrxxxxbrxx Prolxxbrxxxxbrxxxxbrxxxxbrxx Thexxbrxxxxbrxxxxbrxx Preludexxbrxxxxbrxxxxbrxx Pxxbrxxxxbrxxxxbrxx Txxbrxxxxbrxxxxbrxx Sxxbrxxxxbrxxxxbrxx _xxbrxxxxbrxxxxbrxx Dxxbrxxxxbrxxxxbrxx Exxbrxxxxbrxxxxbrxx Cxxbrxxxxbrxxxxbrxx Axxbrxxxxbrxxxxbrxx Gxxbrxxxxbrxxxxbrxx -xxbrxxxxbrxxxxbrxx Lxxbrxxxxbrxxxxbrxx N\""
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(ds[0]).unsqueeze(0)\n",
    "gen = model.generate(x, max_length=112, min_length=10, \n",
    "                      repetition_penalty=10, no_repeat_ngram_size=4,\n",
    "                      early_stopping=True, do_sample=True, temperature=.7)\n",
    "tok.decode(gen.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T01:01:04.129879Z",
     "start_time": "2020-06-08T01:01:01.499158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"xxbrxxPROLOGUE\\n\\nLift had never robbed a palace before. Seemed like a dangerous thing to try.\\nNot because she might get caught, but because once you robbed a starvin'\\npalace, where did you go next? And even then... LIFT was very good at knowing when the enemy's king would come and tell them he didn't want him there anymore! You have no idea how many times I've been on this ship over my life… But that guy just got out of his seat right now (and is still in\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = model.generate(x, bad_words_ids=[[len(tok)-1]], max_length=112,\n",
    "                     min_length=10, repetition_penalty=10, no_repeat_ngram_size=4,\n",
    "                      early_stopping=True, do_sample=True, temperature=.7)\n",
    "tok.decode(gen.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T01:01:26.733646Z",
     "start_time": "2020-06-08T01:01:26.685946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"xxbrxxPROLOGUE\\n\\nLift had never robbed a palace before. Seemed like a dangerous thing to try.\\nNot because she might get caught, but because once you robbed a starvin'\\npalace, where did you go next?\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode(x[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T05:08:06.457685Z",
     "start_time": "2020-06-03T05:08:06.417866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Huqin turned to one of his companions. Using their ropes, they scuttled'"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode(list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T03:49:44.402934Z",
     "start_time": "2020-06-03T03:49:37.107903Z"
    }
   },
   "outputs": [],
   "source": [
    "# - num_beams: larger -> slower but better results.\n",
    "# - num_return_sequences: must be <= num_beams\n",
    "# - output: (bs*num_return_sequences, seq_len)\n",
    "# - no_repeat_ngram_size: very effective at reducing repetition but use carefully,\n",
    "# if we generate a long piece of text all at once this persists. Maybe we can generate in chunks?\n",
    "# - temperature: 0 means greedy, 1 means more randomness which can be risky\n",
    "# - blog suggests top k search (top_k=50) or top p search may be good for \n",
    "# story generation, while beam search is better for machine translation \n",
    "# (still need do_sample=True)\n",
    "pred = model.generate(x.unsqueeze(0), max_length=60, min_length=10, \n",
    "                      repetition_penalty=10, no_repeat_ngram_size=3,\n",
    "                      num_return_sequences=3, num_beams=4,\n",
    "                      early_stopping=True, do_sample=True, temperature=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T03:49:44.515526Z",
     "start_time": "2020-06-03T03:49:44.409807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Huqin turned to one of his companions. Using their ropes, they scuttled off into the distance with a loud thud and an explosion shook them all away from each other\\'s eyes as if nothing had happened at that moment.\"\\n\"What are you talking about?\" he asked'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode(list(pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T03:49:44.582696Z",
     "start_time": "2020-06-03T03:49:44.518059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Huqin turned to one of his companions. Using their ropes, they scuttled off into the forest and disappeared in a flash as if nothing had happened at all.\"\\n\"What did you do?\" asked Ye Xiwen with an expression that seemed like it was about time for'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode(list(pred[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T03:49:44.655642Z",
     "start_time": "2020-06-03T03:49:44.586983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Huqin turned to one of his companions. Using their ropes, they scuttled out the door and ran into a small room with an old man sitting on it waiting for them in order that he might take care not only himself but also those around him who were watching from afar as'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode(list(pred[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T05:10:04.923168Z",
     "start_time": "2020-06-03T05:10:02.779769Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = model.generate(torch.tensor(ds[800]).unsqueeze(0),\n",
    "                      max_length=60, min_length=10, top_k=50, \n",
    "                      early_stopping=True, do_sample=True, temperature=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T05:10:16.386703Z",
     "start_time": "2020-06-03T05:10:16.344470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Something stirred inside of Lift. Like the little swirls of wind at the advent'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode(ds[800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T05:11:03.257226Z",
     "start_time": "2020-06-03T05:11:03.211934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('of a storm.', 'Darkness looked at her with a sharp motion. \"Something is--\"')"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode(ds[801]), tok.decode(ds[802])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T05:10:33.486020Z",
     "start_time": "2020-06-03T05:10:33.405900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22210, 33091,  2641,   286, 43711,    13,  4525,   262,  1310, 42835,\n",
       "            82,   286,  2344,   379,   262, 19980,   286,   262,  2344,    11,\n",
       "           810,   790,  1657,  3947,   284,  5202,   832,   340,    11,  1865,\n",
       "           262,  1657,  2346,   373,   991,    13,   198,   198,     6,    40,\n",
       "          4724,   340,   338,   407,   355,  1290,   503,   355,   314,  1807,\n",
       "            13,   632,   338,   655,   257,  3155,   286,  2431,   656,   262]])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T05:10:42.828951Z",
     "start_time": "2020-06-03T05:10:42.765548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Something stirred inside of Lift. Like the little swirls of wind at the advent of the wind, where every light seemed to flow through it, yet the light itself was still.\\n\\n'I guess it's not as far out as I thought. It's just a couple of minutes into the\""
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode(list(pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T04:17:41.519631Z",
     "start_time": "2020-06-09T04:17:41.412513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.get_vocab()['xxbrxx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T03:42:16.582611Z",
     "start_time": "2020-06-20T03:42:16.512137Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_to_file(model, tok, x, path, *skip_tokens, max_length=112, \n",
    "                     mode='a', verbose=True, **kwargs):\n",
    "    if not isinstance(x, torch.Tensor):\n",
    "        x = torch.tensor(x)\n",
    "    if len(x.shape) == 1:\n",
    "        x = x.unsqueeze(0)\n",
    "        \n",
    "    kwargs_ = dict(max_length=max_length, min_length=10, \n",
    "                   repetition_penalty=10, no_repeat_ngram_size=4, \n",
    "                   early_stopping=True, do_sample=True, temperature=.7, \n",
    "                   top_p=.95, top_k=max_length,\n",
    "                   bad_words_ids=[[tok.get_vocab()[t] for t in skip_tokens]]\n",
    "                                  if skip_tokens else None)\n",
    "    # Update after so defaults are overwritten if user provides value.\n",
    "    kwargs_.update(kwargs)\n",
    "    res = model.generate(x, **kwargs_)[0].numpy().tolist()\n",
    "    old, new = map(tok.decode, (res[:len(x[0])], res[len(x[0]):]))\n",
    "    if verbose:\n",
    "        print(old, '\\n\\n', new)\n",
    "    save(spacer()+old+new+spacer(), path, mode_pre=mode, verbose=verbose)\n",
    "    return old, new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T04:32:16.974500Z",
     "start_time": "2020-06-09T04:31:58.233276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " or use it again.\n",
      "Szeth lowered his Shardblade, standing among the cinder-eyed corpses. Here, in\n",
      "Alethkar, men often spoke of the legends--of mankind's hard-won victory over the\n",
      "Void \n",
      "\n",
      "  dragons and their treacherous servants who came to battle our heroes; they were called \"the dead,\" even now! There is no such thing as a life without death itself... And I am glad that my people can finally make contact with each other once more: for this great city stands today...\" He looked at Ale\n"
     ]
    }
   ],
   "source": [
    "res = generate_to_file(model, tok, ds[800], 'data/generated/sample.txt', \n",
    "                       'xxbrxx', mode='w', max_length=112)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
